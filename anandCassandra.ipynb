{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974a05cc-db19-4a7a-8efe-521ff139f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "import json\n",
    "from cassandra.query import SimpleStatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eca41a7-e87e-4948-853b-c3f2bf40feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to connect to Cassandra\n",
    "def connect_to_cassandra():\n",
    "    cloud_config = {\n",
    "        'secure_connect_bundle': 'secure-connect-salesdatabase.zip'\n",
    "    }\n",
    "    with open(\"salesdatabase-token.json\") as f:\n",
    "        secrets = json.load(f)\n",
    "\n",
    "    CLIENT_ID = secrets[\"clientId\"]\n",
    "    CLIENT_SECRET = secrets[\"secret\"]\n",
    "\n",
    "    auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
    "    cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "    session = cluster.connect()\n",
    "    return session, cluster  # Returns both session and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e90d93bc-50cb-48dc-b1ff-3db684229747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(session, keyspace, table, df):\n",
    "    # loading raw data into database\n",
    "    try:\n",
    "        # Modify the table schema (column names)\n",
    "        session.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {keyspace}.{table} (\n",
    "            region_name TEXT,\n",
    "            country_name TEXT,\n",
    "            item_category TEXT,\n",
    "            sales_channel TEXT,\n",
    "            order_priority TEXT,\n",
    "            order_date TEXT,\n",
    "            order_id BIGINT PRIMARY KEY,\n",
    "            shipping_date TEXT,\n",
    "            units_sold INT,\n",
    "            unit_price FLOAT,\n",
    "            unit_cost FLOAT,\n",
    "            total_revenue FLOAT,\n",
    "            total_cost FLOAT,\n",
    "            total_profit FLOAT\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # Prepare the insert query with modified column names\n",
    "        insert_query = session.prepare(f\"\"\"\n",
    "        INSERT INTO {keyspace}.{table} (\n",
    "            region_name, country_name, item_category, sales_channel, order_priority,\n",
    "            order_date, order_id, shipping_date, units_sold, unit_price,\n",
    "            unit_cost, total_revenue, total_cost, total_profit\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\")\n",
    "\n",
    "        # Insert each row into the Cassandra table\n",
    "        for _, row in df.iterrows():\n",
    "            session.execute(insert_query, (\n",
    "                row['Region'], row['Country'], row['Item Type'], row['Sales Channel'],\n",
    "                row['Order Priority'], row['Order Date'], row['Order ID'], row['Ship Date'],\n",
    "                row['UnitsSold'], row['UnitPrice'], row['UnitCost'],\n",
    "                row['TotalRevenue'], row['TotalCost'], row['TotalProfit']\n",
    "            ))\n",
    "\n",
    "        print(\"CSV data successfully loaded into Cassandra!(Bronze table)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb28046-f4a6-4086-afec-62812ac2dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def bronze_to_silver(dataframe):\n",
    "    \"\"\"\n",
    "    Cleans and processes the bronze-level DataFrame to silver-level.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle missing values: Drop rows where critical fields are null\n",
    "        critical_columns = [\n",
    "            \"region_name\", \"country_name\", \"item_category\", \"sales_channel\", \n",
    "            \"order_priority\", \"order_date\", \"order_id\", \"shipping_date\"\n",
    "        ]\n",
    "        dataframe = dataframe.dropna(subset=critical_columns)\n",
    "        \n",
    "        # Ensuring correct data types\n",
    "        dataframe[\"order_id\"] = dataframe[\"order_id\"].astype(int)\n",
    "        dataframe[\"units_sold\"] = dataframe[\"units_sold\"].astype(int)\n",
    "        dataframe[\"unit_price\"] = dataframe[\"unit_price\"].astype(float)\n",
    "        dataframe[\"unit_cost\"] = dataframe[\"unit_cost\"].astype(float)\n",
    "        dataframe[\"total_revenue\"] = dataframe[\"total_revenue\"].astype(float)\n",
    "        dataframe[\"total_cost\"] = dataframe[\"total_cost\"].astype(float)\n",
    "        dataframe[\"total_profit\"] = dataframe[\"total_profit\"].astype(float)\n",
    "        \n",
    "        # Converting dates to uniform format\n",
    "        date_format = \"%m/%d/%Y\"\n",
    "        dataframe[\"order_date\"] = pd.to_datetime(dataframe[\"order_date\"], format=date_format, errors=\"coerce\")\n",
    "        dataframe[\"shipping_date\"] = pd.to_datetime(dataframe[\"shipping_date\"], format=date_format, errors=\"coerce\")\n",
    "        \n",
    "        # Removing rows with invalid dates\n",
    "        dataframe = dataframe.dropna(subset=[\"order_date\", \"shipping_date\"])\n",
    "        \n",
    "        # Standardizing categorical fields to lowercase\n",
    "        dataframe[\"region_name\"] = dataframe[\"region_name\"].str.lower()\n",
    "        dataframe[\"country_name\"] = dataframe[\"country_name\"].str.lower()\n",
    "        dataframe[\"item_category\"] = dataframe[\"item_category\"].str.lower()\n",
    "        dataframe[\"sales_channel\"] = dataframe[\"sales_channel\"].str.lower()\n",
    "        dataframe[\"order_priority\"] = dataframe[\"order_priority\"].str.lower()\n",
    "        \n",
    "        # Removing invalid records: Check if order_date <= shipping_date\n",
    "        dataframe = dataframe[dataframe[\"order_date\"] <= dataframe[\"shipping_date\"]]\n",
    "        \n",
    "        # Add a \"processed_at\" column to track processing time\n",
    "        dataframe[\"processed_at\"] = datetime.now()\n",
    "        \n",
    "        return dataframe\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing the data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c4a9cc6-9950-4172-9bf9-fdb4cef03cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_cassandra(silver_df, keyspace, silvertable):\n",
    "    try:\n",
    "        # Create the table with updated column names\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {keyspace}.{silvertable} (\n",
    "            order_id BIGINT PRIMARY KEY,\n",
    "            country_name TEXT,\n",
    "            item_category TEXT,\n",
    "            order_date DATE,\n",
    "            order_priority TEXT,\n",
    "            region_name TEXT,\n",
    "            sales_channel TEXT,\n",
    "            shipping_date DATE,\n",
    "            total_cost FLOAT,\n",
    "            total_profit FLOAT,\n",
    "            total_revenue FLOAT,\n",
    "            unit_cost FLOAT,\n",
    "            unit_price FLOAT,\n",
    "            units_sold INT,\n",
    "            processed_at TIMESTAMP\n",
    "        );\n",
    "        \"\"\"\n",
    "        session.execute(create_table_query)\n",
    "\n",
    "        # Prepare the insert query with updated column names\n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO {keyspace}.{silvertable} (\n",
    "            order_id, country_name, item_category, order_date, order_priority, \n",
    "            region_name, sales_channel, shipping_date, total_cost, total_profit, \n",
    "            total_revenue, unit_cost, unit_price, units_sold, processed_at\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        prepared = session.prepare(insert_query)\n",
    "\n",
    "        # Insert the data row by row\n",
    "        for _, row in silver_df.iterrows():\n",
    "            session.execute(prepared, (\n",
    "                int(row[\"order_id\"]),\n",
    "                row[\"country_name\"],\n",
    "                row[\"item_category\"],\n",
    "                row[\"order_date\"].date(),\n",
    "                row[\"order_priority\"],\n",
    "                row[\"region_name\"],\n",
    "                row[\"sales_channel\"],\n",
    "                row[\"shipping_date\"].date(),\n",
    "                float(row[\"total_cost\"]),\n",
    "                float(row[\"total_profit\"]),\n",
    "                float(row[\"total_revenue\"]),\n",
    "                float(row[\"unit_cost\"]),\n",
    "                float(row[\"unit_price\"]),\n",
    "                int(row[\"units_sold\"]),\n",
    "                row[\"processed_at\"].to_pydatetime()\n",
    "            ))\n",
    "\n",
    "        print(\"Silver data loaded successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading data to Cassandra: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235f5b2a-a9ab-41db-948c-e259e22f0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_table1(silver_df):\n",
    "    \"\"\"\n",
    "    Top 5 countries by total revenue by region.\n",
    "    \"\"\"\n",
    "    gold_table1 = (\n",
    "        silver_df.groupby([\"region_name\", \"country_name\"], as_index=False)\n",
    "        .agg(total_revenue=(\"total_revenue\", \"sum\"))\n",
    "    )\n",
    "    gold_table1 = (\n",
    "        gold_table1.sort_values(by=[\"region_name\", \"total_revenue\"], ascending=[True, False])\n",
    "        .groupby(\"region_name\")\n",
    "        .head(5)\n",
    "    )\n",
    "    return gold_table1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd9ee1f5-3c2f-4694-adc2-36cdc019398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_table2(silver_df):\n",
    "    \"\"\"\n",
    "    Region wise average unit price by item category.\n",
    "    \"\"\"\n",
    "    gold_table2 = silver_df.groupby(['region_name', 'item_category']).agg(\n",
    "        avg_unit_price=('unit_price', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    return gold_table2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a59f278-6185-4fcf-aea6-0c238d51085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_table3(silver_df):\n",
    "    \"\"\"Yearly total cost and total units sold by item category\"\"\"\n",
    "    silver_df[\"year\"] = silver_df[\"order_date\"].dt.to_period(\"Y\").astype(str)  # Extract Year\n",
    "    gold_table = (\n",
    "        silver_df.groupby([\"item_category\", \"year\"], as_index=False)\n",
    "        .agg(\n",
    "            total_cost=(\"total_cost\", \"sum\"),\n",
    "            total_units_sold=(\"units_sold\", \"sum\")\n",
    "        )\n",
    "    )\n",
    "    return gold_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4c6a52-dd49-4ad7-a5e2-756934a456e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gold_table_to_cassandra(df, keyspace, table_name, schema_query, insert_query):\n",
    "    session.execute(schema_query) \n",
    "    prepared = session.prepare(insert_query)\n",
    "    for _, row in df.iterrows():\n",
    "        session.execute(prepared, tuple(row))\n",
    "    print(f\"Data loaded successfully into {table_name}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f5d7b6-49e1-4c6e-9d52-70e8bb253dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_countries_by_revenue(gold_table1, keyspace=\"s2\"):  # gold table 1 (modified)\n",
    "    schema_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.top_countries_by_revenue (\n",
    "        region_name TEXT,\n",
    "        country_name TEXT,\n",
    "        total_revenue FLOAT,\n",
    "        PRIMARY KEY (region_name, country_name)\n",
    "    );\n",
    "    \"\"\"\n",
    "    insert_query = f\"\"\"\n",
    "    INSERT INTO {keyspace}.top_countries_by_revenue (region_name, country_name, total_revenue)\n",
    "    VALUES (?, ?, ?);\n",
    "    \"\"\"\n",
    "    load_gold_table_to_cassandra(\n",
    "        gold_table1,\n",
    "        keyspace,\n",
    "        \"top_countries_by_revenue\",\n",
    "        schema_query,\n",
    "        insert_query\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a32834-2e9f-4b1b-bd62-a4a46bc07569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_itemtype_avg_unit_price(gold_table2, keyspace=\"s2\"):  # gold table 2 (modified)\n",
    "    schema_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.region_itemtype_avg_unit_price (\n",
    "        region_name TEXT,\n",
    "        item_category TEXT,\n",
    "        avg_unit_price FLOAT,\n",
    "        PRIMARY KEY (region_name, item_category)\n",
    "    );\n",
    "    \"\"\"\n",
    "    insert_query = f\"\"\"\n",
    "    INSERT INTO {keyspace}.region_itemtype_avg_unit_price (region_name, item_category, avg_unit_price)\n",
    "    VALUES (?, ?, ?);\n",
    "    \"\"\"\n",
    "    load_gold_table_to_cassandra(\n",
    "        gold_table2,\n",
    "        keyspace,\n",
    "        \"region_itemtype_avg_unit_price\",\n",
    "        schema_query,\n",
    "        insert_query\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae1d7bf-c78e-4e05-8f8b-3704be019aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_item_performance(gold_table3, keyspace=\"s2\"):  # gold table 3 (modified)\n",
    "    schema_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {keyspace}.annual_item_performance (\n",
    "        item_category TEXT,\n",
    "        year TEXT,\n",
    "        total_cost FLOAT,\n",
    "        total_units_sold INT,\n",
    "        PRIMARY KEY (item_category, year)\n",
    "    );\n",
    "    \"\"\"\n",
    "    insert_query = f\"\"\"\n",
    "    INSERT INTO {keyspace}.annual_item_performance (item_category, year, total_cost, total_units_sold)\n",
    "    VALUES (?, ?, ?, ?);\n",
    "    \"\"\"\n",
    "    load_gold_table_to_cassandra(\n",
    "        gold_table3,\n",
    "        keyspace,\n",
    "        \"annual_item_performance\",\n",
    "        schema_query,\n",
    "        insert_query\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4f5dc3c-ba8c-45c0-a89d-c60b93e4b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully loaded into Cassandra!(Bronze table)\n",
      "Data Extracted Successfully!\n",
      "Silver data loaded successfully!\n",
      "Data loaded successfully into top_countries_by_revenue!\n",
      "Data loaded successfully into region_itemtype_avg_unit_price!\n",
      "Data loaded successfully into annual_item_performance!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    session, cluster = connect_to_cassandra()\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/gchandra10/filestorage/main/sales_100.csv\")\n",
    "    keyspace = 's2'  # Changed keyspace to 's2'\n",
    "    table = 'bronzesales'\n",
    "\n",
    "    # Loading raw data into bronze table\n",
    "    load(session, keyspace, table, df)\n",
    "\n",
    "    # Extracting data from the bronze table\n",
    "    query = f\"SELECT * FROM {keyspace}.{table}\"\n",
    "    rows = session.execute(query)\n",
    "    data = [row._asdict() for row in rows]\n",
    "    df1 = pd.DataFrame(data)\n",
    "    print('Data Extracted Successfully!')\n",
    "\n",
    "    # Cleaning the data (making it suitable for the silver stage)\n",
    "    silver_df = bronze_to_silver(df1)\n",
    "\n",
    "    # Loading silver data to Cassandra\n",
    "    silvertable = \"silversales\"\n",
    "    load_to_cassandra(silver_df, keyspace, silvertable)\n",
    "\n",
    "    # Generating Gold tables\n",
    "    gold_table1 = gold_table1(silver_df)\n",
    "    gold_table2 = gold_table2(silver_df)\n",
    "    gold_table3 = gold_table3(silver_df)\n",
    "\n",
    "    # Loading gold tables to Cassandra\n",
    "    top_countries_by_revenue(gold_table1, keyspace=\"s2\")  # Adjusted to 's2'\n",
    "    region_itemtype_avg_unit_price(gold_table2, keyspace=\"s2\")  # Adjusted to 's2'\n",
    "    annual_item_performance(gold_table3, keyspace=\"s2\")  # Adjusted to 's2'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
